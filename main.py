# main.py
# ================================================================
# VIETLOTT 6/45 - ULTRA PIPELINE V7 (ENHANCED WITH PROBABILITY OUTPUT)
# ================================================================
# C·∫£i ti·∫øn:
# - Features: TƒÉng t·ª´ 300 l√™n 600+ features (Pair/Triplet, Hot/Cold, Zone, Gap)
# - Models: Weighted ensemble v·ªõi early stopping
# - Output: X√°c su·∫•t cho t·∫•t c·∫£ 45 s·ªë thay v√¨ ch·ªâ top-K
# ================================================================

import os
import numpy as np
import warnings
from sklearn.preprocessing import MultiLabelBinarizer

# Import c√°c module t·ª´ th∆∞ m·ª•c src
from src.data_loader import LotteryDataLoader
from src.features import UltraFeatureEngine
from src.models import UltraModelManager
from src.tuner import UltraTuner
from src.visualizer import ProbabilityVisualizer
from src.evaluator import LotteryEvaluator

# --- C·∫§U H√åNH ---
# Quan tr·ªçng: ƒê·∫∑t FORCE_RETRAIN = True cho l·∫ßn ch·∫°y ƒë·∫ßu ti√™n n√†y 
# ƒë·ªÉ x√≥a b·ªè model "ngu" (train b·∫±ng dummy data) v√† train l·∫°i b·∫±ng data th·∫≠t.
RUN_TUNING = True # ch·∫°y 1 l·∫ßn r·ªìi t·∫Øt ƒëi
FORCE_RETRAIN = True 
PAST_WINDOW = 100   # Nh√¨n l·∫°i 100 k·ª≥ qu√° kh·ª©
TEST_SIZE = 50      # D√πng 50 k·ª≥ cu·ªëi ƒë·ªÉ ki·ªÉm tra ƒë·ªô ch√≠nh x√°c
TOP_K = 8           # G·ª£i √Ω top 8 s·ªë

warnings.filterwarnings("ignore")

def main():
    print("\n" + "="*50)
    print("   üöÄ VIETLOTT ULTRA ENSEMBLE V4 - REAL DATA MODE")
    print("="*50)

    # ------------------------------------------------------
    # B∆Ø·ªöC 1: DATA LAYER (N·∫†P FILE NPY)
    # ------------------------------------------------------
    print("\n[1/5] üì• DATA LAYER")
    loader = LotteryDataLoader()
    
    # --- ƒêO·∫†N QUAN TR·ªåNG NH·∫§T ---
    # ƒê·ªçc file lottery_data.npy c·ªßa b·∫°n
    # H√£y ch·∫Øc ch·∫Øn file n√†y n·∫±m c√πng c·∫•p v·ªõi main.py
    loader.import_from_npy("lottery_data.npy")
    
    df = loader.load_data()
    print(f"   -> ƒê√£ t·∫£i th√†nh c√¥ng {len(df)} k·ª≥ quay.")

    # ------------------------------------------------------
    # B∆Ø·ªöC 2: FEATURE ENGINEERING (T·∫†O ƒê·∫∂C TR∆ØNG)
    # ------------------------------------------------------
    print("\n[2/5] ‚öôÔ∏è  FEATURE ENGINEERING")
    
    feat_engine = UltraFeatureEngine(past_window=PAST_WINDOW)
    X, y = feat_engine.prepare_training_dataset(df)
    
    mlb = MultiLabelBinarizer(classes=range(1, 46))
    y_bin = mlb.fit_transform(y)
    
    # --- CHIA DATA: TRAIN - VAL - TEST ---
    # Test: 50 k·ª≥ cu·ªëi
    # Val:  50 k·ª≥ tr∆∞·ªõc Test (ƒë·ªÉ Early Stopping)
    # Train: C√≤n l·∫°i
    VAL_SIZE = 50 
    
    X_full_train = X[:-TEST_SIZE]
    y_full_train = y_bin[:-TEST_SIZE]
    
    X_test = X[-TEST_SIZE:]
    y_test = y_bin[-TEST_SIZE:]
    
    # Chia ti·∫øp Full Train th√†nh Train v√† Val
    X_train = X_full_train[:-VAL_SIZE]
    y_train = y_full_train[:-VAL_SIZE]
    X_val   = X_full_train[-VAL_SIZE:]
    y_val   = y_full_train[-VAL_SIZE:]

    print(f"   -> Data Splits:")
    print(f"      + Train: {X_train.shape[0]} (D√πng ƒë·ªÉ d·∫°y Model)")
    print(f"      + Val  : {X_val.shape[0]}   (D√πng ƒë·ªÉ ch·ªânh Early Stopping)")
    print(f"      + Test : {X_test.shape[0]}  (D√πng ƒë·ªÉ ki·ªÉm tra cu·ªëi c√πng)")
    
    # B∆Ø·ªöC 2.5: HYPERPARAMETER TUNING (OPTUNA)
    if RUN_TUNING:
        print("\n[2.5] üß™ HYPERPARAMETER TUNING (OPTUNA)")
        # L∆∞u √Ω: Tuner n√™n d√πng X_full_train ƒë·ªÉ t√¨m tham s·ªë t·ªët nh·∫•t
        tuner = UltraTuner(X_full_train, y_full_train) 
        tuner.run_optimization(n_trials=10)

    # ------------------------------------------------------
    # B∆Ø·ªöC 3: MODEL TRAINING (HU·∫§N LUY·ªÜN)
    # ------------------------------------------------------
    print("\n[3/5] üß† MODEL FACTORY")
    manager = UltraModelManager(model_path="data/ultra_ensemble_v4.pkl")
    
    if FORCE_RETRAIN or not os.path.exists(manager.model_path):
        print("   ‚ö†Ô∏è  Ph√°t hi·ªán y√™u c·∫ßu Retrain. ƒêang hu·∫•n luy·ªán l·∫°i...")
        # TRUY·ªÄN TH√äM X_val, y_val V√ÄO ƒê√ÇY
        manager.train_all(X_train, y_train, X_val, y_val)
    else:
        print("   ‚úÖ ƒê√£ t√¨m th·∫•y Model c≈©. ƒêang t·∫£i l√™n...")
        manager.load_models()
        
    print(f"   -> C√°c Model ho·∫°t ƒë·ªông: {list(manager.models.keys())}")

    # ------------------------------------------------------
    # B∆Ø·ªöC 4: ƒê√ÅNH GI√Å HI·ªÜU SU·∫§T TO√ÄN DI·ªÜN
    # ------------------------------------------------------
    print(f"\n[4/5] üèÅ KI·ªÇM TH·ª¨ TR√äN {TEST_SIZE} K·ª≤ CU·ªêI")
    
    # D·ª± b√°o cho to√†n b·ªô test set
    print("   ‚Æû ƒêang d·ª± b√°o cho test set...")
    test_predictions = []
    for i in range(len(X_test)):
        probas = manager.predict_ensemble(X_test[i].reshape(1, -1))
        test_predictions.append(probas)
    
    test_predictions = np.array(test_predictions)
    
    # Hi·ªÉn th·ªã m·ªôt v√†i k·ª≥ m·∫´u
    print("\n   üìã M·∫™U D·ª∞ ƒêO√ÅN (3 k·ª≥ cu·ªëi):")
    for i in range(max(0, len(X_test) - 3), len(X_test)):
        probas = test_predictions[i]
        top_indices = np.argsort(probas)[-TOP_K:][::-1]
        pred_nums = [idx + 1 for idx in top_indices]
        actual_indices = np.where(y_test[i] == 1)[0]
        actual_nums = [idx + 1 for idx in actual_indices]
        hits = len(set(pred_nums) & set(actual_nums))
        real_idx = len(X_train) + i + 1
        print(f"      K·ª≥ {real_idx}: D·ª± ƒëo√°n {[int(x) for x in sorted(pred_nums)]} | KQ {[int(x) for x in sorted(actual_nums)]} | Tr√∫ng: {hits}")
    
    # ƒê√°nh gi√° to√†n di·ªán
    evaluator = LotteryEvaluator(top_k=TOP_K)
    evaluation_results = evaluator.comprehensive_evaluate(test_predictions, y_test)
    
    # In b√°o c√°o
    evaluator.print_evaluation_report(evaluation_results)
    
    # Hi·ªÉn th·ªã ph√¢n ph·ªëi x√°c su·∫•t trung b√¨nh tr√™n test set
    print(f"\n   üìà PH√ÇN T√çCH X√ÅC SU·∫§T TRUNG B√åNH TR√äN TEST SET:")
    avg_probas = np.mean(test_predictions, axis=0)
    top_5_avg = np.argsort(avg_probas)[-5:][::-1]
    print(f"      Top 5 s·ªë c√≥ x√°c su·∫•t trung b√¨nh cao nh·∫•t:")
    for idx in top_5_avg:
        print(f"         S·ªë {idx+1}: {avg_probas[idx]:.4f} ({avg_probas[idx]*100:.2f}%)")

    # ------------------------------------------------------
    # B∆Ø·ªöC 5: D·ª∞ B√ÅO T∆Ø∆†NG LAI V·ªöI X√ÅC SU·∫§T
    # ------------------------------------------------------
    print("\n" + "="*80)
    print(f"üî• D·ª∞ B√ÅO K·ª≤ TI·∫æP THEO (Index {len(df) + 1}) - X√ÅC SU·∫§T")
    print("="*80)
    
    future_feat = feat_engine.create_single_feature(df, len(df))
    future_probas = manager.predict_ensemble(future_feat.reshape(1, -1))
    
    # S·ª≠ d·ª•ng Visualizer ƒë·ªÉ hi·ªÉn th·ªã
    visualizer = ProbabilityVisualizer()
    
    # Hi·ªÉn th·ªã b·∫£ng x√°c su·∫•t ƒë·∫ßy ƒë·ªß
    visualizer.print_probability_table(future_probas, top_n=45)
    
    # Hi·ªÉn th·ªã top K s·ªë
    print(f"\nüéØ TOP {TOP_K} S·ªê C√ì X√ÅC SU·∫§T CAO NH·∫§T:")
    print("-" * 80)
    top_numbers = visualizer.get_top_numbers(future_probas, k=TOP_K)
    for i, (num, prob) in enumerate(top_numbers, 1):
        level = ProbabilityVisualizer._get_probability_level(prob)
        bar = "‚ñà" * int(prob * 40)
        print(f"  {i:2d}. S·ªë {num:2d}: {prob:.6f} ({prob*100:5.2f}%) {level:>12} {bar}")
    
    # Hi·ªÉn th·ªã t√≥m t·∫Øt
    visualizer.print_probability_summary(future_probas)
    
    # Ph√¢n t√≠ch theo v√πng v√† ch·∫µn/l·∫ª
    visualizer.print_zone_analysis(future_probas)
    
    print("="*80)
    
    # Xu·∫•t dictionary x√°c su·∫•t (c√≥ th·ªÉ l∆∞u v√†o file n·∫øu c·∫ßn)
    probability_dict = visualizer.export_probabilities_to_dict(future_probas)
    print(f"\nüíæ X√°c su·∫•t ƒë√£ ƒë∆∞·ª£c t√≠nh to√°n cho t·∫•t c·∫£ 45 s·ªë.")
    print(f"   B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng probability_dict ƒë·ªÉ l∆∞u ho·∫∑c x·ª≠ l√Ω th√™m.")

if __name__ == "__main__":
    main()
